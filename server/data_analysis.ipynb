{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from pymongo import MongoClient\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from itertools import permutations\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost\", 27017)\n",
    "job_table = client[\"job-search-database\"][\"jobs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "link_pattern = re.compile('<a href[^<]+</a>')\n",
    "noise_pattern = re.compile('^\\W$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_sentence = '<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(job):\n",
    "    job = job.lower()\n",
    "    job = link_pattern.sub('', job)\n",
    "    job = (\n",
    "        job.replace('<p>', '')\n",
    "        .replace('&#x27;', \"'\")\n",
    "        .replace('&quot;', '\"')\n",
    "        .replace('|', '')\n",
    "    )\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(job)\n",
    "    tokens = [ t if t != '.' else end_of_sentence for t in tokens ] # For synthetic data shuffling\n",
    "    tokens = [ t for t in tokens if should_keep_token(t) ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_keep_token(token):\n",
    "    return (\n",
    "        re.match(noise_pattern, token) == None and\n",
    "        not token.startswith('@') and\n",
    "        not token.startswith('#')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    data.drop(['_id', 'by', 'id', 'parent', 'date'], axis=1, inplace=True)\n",
    "    data = data[data['text'].isnull() == False]\n",
    "    data = data[data['preferred'].isnull() == False]\n",
    "    data['preferred'] = data['preferred'].map(lambda x: 1 if x else 0)\n",
    "    data['tokens'] = data['text'].map(tokenize)\n",
    "    data = data[data.tokens != 'NC']\n",
    "    data = data[data.tokens.apply(lambda x: len(x) > 20)]\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred = pandas.DataFrame(job_table.find({ '$and': [{ 'preferred': { '$exists': True } }, { 'text': { '$exists': True } }] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = process(preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = processed[processed['preferred'] == 1]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(i, available_splits, total_splits):\n",
    "    return ((i + 1) * max((available_splits // total_splits), 1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sentences(tokens, max_splits = 2):\n",
    "    av_splits = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] == end_of_sentence and i != 0 and i != (len(tokens) - 1):\n",
    "            av_splits.append(i)\n",
    "\n",
    "    collection = []\n",
    "    total_splits = min(max_splits, len(av_splits))\n",
    "    calc_split = lambda x: find_split(x, len(av_splits), total_splits)\n",
    "\n",
    "    if total_splits == 0:\n",
    "        collection.append(tokens)\n",
    "    else:\n",
    "        for i in range(total_splits + 1): # total groups is 1 more than total splits\n",
    "            if i == 0:\n",
    "                collection.append(tokens[:av_splits[calc_split(i)]])\n",
    "            elif i == total_splits:\n",
    "                collection.append(tokens[av_splits[calc_split(i - 1)]:])\n",
    "            else:\n",
    "                collection.append(tokens[av_splits[calc_split(i - 1)]: av_splits[calc_split(i)]])\n",
    "\n",
    "    return collection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    return [ x for sub in arr for x in sub ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_perm(n):\n",
    "    start = time.time()\n",
    "    perms = list(permutations(grouped[n]))\n",
    "    print(f\"{n} took {time.time() - start} sec\")\n",
    "    return perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "found [27, 54, 115]\ntaking from 27 for i of 0\ntaking from 54 for i of 1\ntaking from 115 for i of 2\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['md.ai',\n  'software',\n  'engineer',\n  'full-time',\n  'new',\n  'york',\n  'ny',\n  'seattle',\n  'wa',\n  'onsite',\n  'or',\n  'remote',\n  'usa',\n  'only',\n  'we',\n  'are',\n  'a',\n  'medical',\n  'ai',\n  'development',\n  'platform',\n  'currently',\n  'focused',\n  'on',\n  'radiology',\n  'pathology',\n  'dermatology'],\n ['<EOS>',\n  'we',\n  'help',\n  'build',\n  'high-quality',\n  'labeled',\n  'datasets',\n  'for',\n  'both',\n  'training',\n  'and',\n  'clinical',\n  'validation',\n  'as',\n  'well',\n  'as',\n  'provide',\n  'tools',\n  'and',\n  'infrastructure',\n  'for',\n  'deploying',\n  'and',\n  'running',\n  'models',\n  'at',\n  'scale'],\n ['<EOS>',\n  'some',\n  'of',\n  'our',\n  'unique',\n  'challenges',\n  'include',\n  'operating',\n  'in',\n  'hipaa-compliant',\n  'environments',\n  'working',\n  'with',\n  'large',\n  'medical',\n  'imaging',\n  'text',\n  'genomic',\n  'datasets',\n  'managing',\n  'machine',\n  'learning',\n  'model',\n  'lifecycles',\n  'and',\n  'building',\n  'complex',\n  'web',\n  'applications',\n  'with',\n  'ui',\n  'ux',\n  'appealing',\n  'to',\n  'both',\n  'doctors',\n  'and',\n  'engineers',\n  'alike.we',\n  'are',\n  'currently',\n  'looking',\n  'for',\n  'front-end',\n  'developers',\n  'react',\n  'graphql',\n  'and',\n  'software',\n  'engineers',\n  'experienced',\n  'in',\n  'devops',\n  'cloud',\n  'technologies',\n  'kubernetes',\n  'docker',\n  'terraform',\n  'gcp',\n  'aws',\n  'azure',\n  '<EOS>',\n  'please',\n  'email',\n  'us',\n  'directly',\n  'at',\n  'jobs@md.ai',\n  '<EOS>']]"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "group_sentences(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = [ group_sentences(tokens) for tokens in samples ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "p = list(permutations(grouped[0]))\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = []\n",
    "for group in grouped:\n",
    "    for x in permutations(group):\n",
    "        my_groups.append(flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "370"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "len(my_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = flatten(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "18"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = []\n",
    "for i in range(len(grouped)):\n",
    "    expanded.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10, 24)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "max_len = 0\n",
    "j = -1\n",
    "for i in range(34):\n",
    "    if len(grouped[i]) > max:\n",
    "        max_len = len(grouped[i])\n",
    "        j = i\n",
    "max, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 took 5.4836273193359375e-06 sec\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(['md.ai',\n   'software',\n   'engineer',\n   'full-time',\n   'new',\n   'york',\n   'ny',\n   'seattle',\n   'wa',\n   'onsite',\n   'or',\n   'remote',\n   'usa',\n   'only',\n   'we',\n   'are',\n   'a',\n   'medical',\n   'ai',\n   'development',\n   'platform',\n   'currently',\n   'focused',\n   'on',\n   'radiology',\n   'pathology',\n   'dermatology'],\n  ['<EOS>',\n   'some',\n   'of',\n   'our',\n   'unique',\n   'challenges',\n   'include',\n   'operating',\n   'in',\n   'hipaa-compliant',\n   'environments',\n   'working',\n   'with',\n   'large',\n   'medical',\n   'imaging',\n   'text',\n   'genomic',\n   'datasets',\n   'managing',\n   'machine',\n   'learning',\n   'model',\n   'lifecycles',\n   'and',\n   'building',\n   'complex',\n   'web',\n   'applications',\n   'with',\n   'ui',\n   'ux',\n   'appealing',\n   'to',\n   'both',\n   'doctors',\n   'and',\n   'engineers',\n   'alike.we',\n   'are',\n   'currently',\n   'looking',\n   'for',\n   'front-end',\n   'developers',\n   'react',\n   'graphql',\n   'and',\n   'software',\n   'engineers',\n   'experienced',\n   'in',\n   'devops',\n   'cloud',\n   'technologies',\n   'kubernetes',\n   'docker',\n   'terraform',\n   'gcp',\n   'aws',\n   'azure',\n   '<EOS>',\n   'please',\n   'email',\n   'us',\n   'directly',\n   'at',\n   'jobs@md.ai',\n   '<EOS>']),\n (['<EOS>',\n   'some',\n   'of',\n   'our',\n   'unique',\n   'challenges',\n   'include',\n   'operating',\n   'in',\n   'hipaa-compliant',\n   'environments',\n   'working',\n   'with',\n   'large',\n   'medical',\n   'imaging',\n   'text',\n   'genomic',\n   'datasets',\n   'managing',\n   'machine',\n   'learning',\n   'model',\n   'lifecycles',\n   'and',\n   'building',\n   'complex',\n   'web',\n   'applications',\n   'with',\n   'ui',\n   'ux',\n   'appealing',\n   'to',\n   'both',\n   'doctors',\n   'and',\n   'engineers',\n   'alike.we',\n   'are',\n   'currently',\n   'looking',\n   'for',\n   'front-end',\n   'developers',\n   'react',\n   'graphql',\n   'and',\n   'software',\n   'engineers',\n   'experienced',\n   'in',\n   'devops',\n   'cloud',\n   'technologies',\n   'kubernetes',\n   'docker',\n   'terraform',\n   'gcp',\n   'aws',\n   'azure',\n   '<EOS>',\n   'please',\n   'email',\n   'us',\n   'directly',\n   'at',\n   'jobs@md.ai',\n   '<EOS>'],\n  ['md.ai',\n   'software',\n   'engineer',\n   'full-time',\n   'new',\n   'york',\n   'ny',\n   'seattle',\n   'wa',\n   'onsite',\n   'or',\n   'remote',\n   'usa',\n   'only',\n   'we',\n   'are',\n   'a',\n   'medical',\n   'ai',\n   'development',\n   'platform',\n   'currently',\n   'focused',\n   'on',\n   'radiology',\n   'pathology',\n   'dermatology'])]"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "time_perm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized = flatten([ list(permutations(group)) for group in grouped ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [ list(permutations(g)) for g in grouped ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'flatten' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-090bb79d8ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flatten' is not defined"
     ]
    }
   ],
   "source": [
    "flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     [md.ai, software, engineer, full-time, new, yo...\n1     [software, engineer, remote, us, canada, full,...\n2     [monadical.com, senior, full-stack, engineer, ...\n3     [revolut, software, engineers, and, many, more...\n4     [proteinqure, computational, drug, design, sen...\n                            ...                        \n72    [genesis, therapeutics, south, san, francisco,...\n73    [rally, health, multiple, openings, back-end, ...\n74    [archerdx, boulder, colorado, software, engine...\n75    [national, robotics, engineering, center, soft...\n76    [10x, genomics, www.10xgenomics.com, pleasanto...\nName: tokens, Length: 77, dtype: object"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "75"
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "len([ x for x in samples if sentence_key in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = [ x[125:] for x in samples if len(x) >= 125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "50"
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "len(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'removed' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5fc74bab80f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mremoved\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'removed' is not defined"
     ]
    }
   ],
   "source": [
    "removed[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(permutations([[\"0\", \"1\"],[\"0\", \"2\"],[\"2\",\"2\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['0', '1'], ['0', '2'], ['2', '2']]"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "list(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['0', '1', '0', '2', '2', '2']"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "[ x for sub in p[0] for x in sub ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitjobsearchpipenva2023f2d64ac47abb087b1cb76916089",
   "display_name": "Python 3.7.6 64-bit ('job-search': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}