{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from pymongo import MongoClient\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from itertools import permutations\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost\", 27017)\n",
    "job_table = client[\"job-search-database\"][\"jobs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "link_pattern = re.compile('<a href[^<]+</a>')\n",
    "noise_pattern = re.compile('^\\W$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_sentence = '<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(job):\n",
    "    job = job.lower()\n",
    "    job = link_pattern.sub('', job)\n",
    "    job = (\n",
    "        job.replace('<p>', '')\n",
    "        .replace('&#x27;', \"'\")\n",
    "        .replace('&quot;', '\"')\n",
    "        .replace('|', '')\n",
    "    )\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(job)\n",
    "    tokens = [ t if t != '.' else end_of_sentence for t in tokens ] # For synthetic data shuffling\n",
    "    tokens = [ t for t in tokens if should_keep_token(t) ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_keep_token(token):\n",
    "    return (\n",
    "        re.match(noise_pattern, token) == None and\n",
    "        not token.startswith('@') and\n",
    "        not token.startswith('#')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    data.drop(['_id', 'by', 'id', 'parent', 'date'], axis=1, inplace=True)\n",
    "    data = data[data['text'].isnull() == False]\n",
    "    data = data[data['preferred'].isnull() == False]\n",
    "    data['preferred'] = data['preferred'].map(lambda x: 1 if x else 0)\n",
    "    data['tokens'] = data['text'].map(tokenize)\n",
    "    data = data[data.tokens != 'NC']\n",
    "    data = data[data.tokens.apply(lambda x: len(x) > 20)]\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred = pandas.DataFrame(job_table.find({ '$and': [{ 'preferred': { '$exists': True } }, { 'text': { '$exists': True } }] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = process(preferred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = processed[processed['preferred'] == 1]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(i, available_splits, total_splits):\n",
    "    return ((i + 1) * max((available_splits // total_splits), 1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_sentences(tokens, max_splits = 2):\n",
    "    av_splits = []\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] == end_of_sentence and i != 0 and i != (len(tokens) - 1):\n",
    "            av_splits.append(i)\n",
    "\n",
    "    collection = []\n",
    "    total_splits = min(max_splits, len(av_splits))\n",
    "    calc_split = lambda x: find_split(x, len(av_splits), total_splits)\n",
    "\n",
    "    if total_splits == 0:\n",
    "        collection.append(tokens)\n",
    "    else:\n",
    "        for i in range(total_splits + 1): # total groups is 1 more than total splits\n",
    "            if i == 0:\n",
    "                collection.append(tokens[:av_splits[calc_split(i)]])\n",
    "            elif i == total_splits:\n",
    "                collection.append(tokens[av_splits[calc_split(i - 1)]:])\n",
    "            else:\n",
    "                collection.append(tokens[av_splits[calc_split(i - 1)]: av_splits[calc_split(i)]])\n",
    "\n",
    "    return collection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    return [ x for sub in arr for x in sub ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_perm(n):\n",
    "    start = time.time()\n",
    "    perms = list(permutations(grouped[n]))\n",
    "    print(f\"{n} took {time.time() - start} sec\")\n",
    "    return perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sentences(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = [ group_sentences(tokens) for tokens in samples ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(permutations(grouped[0]))\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = []\n",
    "for group in grouped:\n",
    "    for x in permutations(group):\n",
    "        my_groups.append(flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = flatten(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = []\n",
    "for i in range(len(grouped)):\n",
    "    expanded.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "j = -1\n",
    "for i in range(34):\n",
    "    if len(grouped[i]) > max:\n",
    "        max_len = len(grouped[i])\n",
    "        j = i\n",
    "max, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_perm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized = flatten([ list(permutations(group)) for group in grouped ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [ list(permutations(g)) for g in grouped ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([ x for x in samples if sentence_key in x ])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitjobsearchpipenva2023f2d64ac47abb087b1cb76916089",
   "display_name": "Python 3.7.6 64-bit ('job-search': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}